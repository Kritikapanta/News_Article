{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971696e5-6947-4e04-ab85-b9e005f14e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== INTERNET NEWS SEARCH ENGINE =====\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter search query (or 'exit'):  climate change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching news from the internet...\n",
      "\n",
      "TOP NEWS RESULTS (BM25 + RM3)\n",
      "\n",
      "1. Climate change threatens Asiaâ€™s water and power systems, reports warn\n",
      "   Source: Yahoo Entertainment\n",
      "   URL: https://www.yahoo.com/news/articles/climate-change-threatens-asia-water-090457889.html\n",
      "\n",
      "2. Federal judge upholds Hawaii's new climate change tax on cruise passengers\n",
      "   Source: Yahoo Entertainment\n",
      "   URL: https://www.yahoo.com/news/articles/federal-judge-upholds-hawaiis-climate-191855471.html\n",
      "\n",
      "3. Study flips ideas about forest soils and climate change\n",
      "   Source: Futurity: Research News\n",
      "   URL: https://www.futurity.org/climate-change-forest-soils-nitrogen-3311372/\n",
      "\n",
      "4. Science still produced many wonders in 2025 despite being under siege\n",
      "   Source: New Scientist\n",
      "   URL: https://www.newscientist.com/article/mg26835732-300-science-still-produced-many-wonders-in-2025-despite-being-under-siege/\n",
      "\n",
      "5. What does climate change look like? This year's hurricane season is one example\n",
      "   Source: NPR\n",
      "   URL: https://www.npr.org/2025/12/24/nx-s1-5620997/2025-hurricane-season-storm-climate-melissa-category-5\n",
      "\n",
      "6. Climate change is rewriting polar bear DNA\n",
      "   Source: Vox\n",
      "   URL: https://www.vox.com/climate/472312/greenland-polar-bears-research-climate-adaptation\n",
      "\n",
      "7. Climate change driving home insurance higher\n",
      "   Source: Flowingdata.com\n",
      "   URL: https://flowingdata.com/2025/12/09/climate-change-driving-home-insurance-higher/\n",
      "\n",
      "8. Iceland declares ocean-current instability a national security risk\n",
      "   Source: Dagens.com\n",
      "   URL: https://www.dagens.com/news/iceland-declares-ocean-current-instability-a-national-security-risk\n",
      "\n",
      "9. What Researchers Are Doing to Protect Christmas Trees in a Warming World\n",
      "   Source: Scientific American\n",
      "   URL: https://www.scientificamerican.com/podcast/episode/what-researchers-are-doing-to-protect-christmas-trees-in-a-warming-world/\n",
      "\n",
      "10. Coca-Cola quietly makes a massive change to its soda brands\n",
      "   Source: TheStreet\n",
      "   URL: https://www.thestreet.com/retail/coca-cola-quietly-makes-a-massive-change-to-its-soda-brands\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "NEWS_API_KEY = \"12ad376c3d5c4134b493484d2711eb14\"\n",
    "ARTICLES_PER_QUERY = 50\n",
    "\n",
    "# =========================\n",
    "# PREPROCESSING\n",
    "# =========================\n",
    "def preprocess(text):\n",
    "    return re.findall(r'\\b\\w+\\b', str(text).lower())\n",
    "\n",
    "# =========================\n",
    "# FETCH NEWS FROM INTERNET\n",
    "# =========================\n",
    "def fetch_news(query, page_size=50):\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"language\": \"en\",\n",
    "        \"pageSize\": page_size,\n",
    "        \"apiKey\": NEWS_API_KEY\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    documents = {}\n",
    "    metadata = {}\n",
    "\n",
    "    for i, article in enumerate(data.get(\"articles\", [])):\n",
    "        content = (article[\"title\"] or \"\") + \" \" + (article[\"description\"] or \"\")\n",
    "        documents[i] = content\n",
    "        metadata[i] = {\n",
    "            \"title\": article[\"title\"],\n",
    "            \"url\": article[\"url\"],\n",
    "            \"source\": article[\"source\"][\"name\"]\n",
    "        }\n",
    "\n",
    "    return documents, metadata\n",
    "\n",
    "# =========================\n",
    "# BUILD INVERTED INDEX\n",
    "# =========================\n",
    "def build_index(documents):\n",
    "    index = defaultdict(list)\n",
    "    doc_lengths = {}\n",
    "    total_terms = 0\n",
    "\n",
    "    for doc_id, text in documents.items():\n",
    "        terms = preprocess(text)\n",
    "        doc_lengths[doc_id] = len(terms)\n",
    "        total_terms += len(terms)\n",
    "\n",
    "        freq = defaultdict(int)\n",
    "        for t in terms:\n",
    "            freq[t] += 1\n",
    "\n",
    "        for term, f in freq.items():\n",
    "            index[term].append((doc_id, f))\n",
    "\n",
    "    avg_dl = total_terms / len(documents)\n",
    "    return index, doc_lengths, avg_dl\n",
    "\n",
    "# =========================\n",
    "# BM25 SCORING\n",
    "# =========================\n",
    "def score_BM25(query, index, doc_lengths, avg_dl, k1=1.5, b=0.75):\n",
    "    scores = defaultdict(float)\n",
    "    N = len(doc_lengths)\n",
    "    query_terms = preprocess(query)\n",
    "\n",
    "    for term in query_terms:\n",
    "        if term not in index:\n",
    "            continue\n",
    "\n",
    "        df = len(index[term])\n",
    "        idf = np.log((N - df + 0.5) / (df + 0.5) + 1)\n",
    "\n",
    "        for doc_id, f in index[term]:\n",
    "            denom = f + k1 * (1 - b + b * (doc_lengths[doc_id] / avg_dl))\n",
    "            scores[doc_id] += idf * (f * (k1 + 1)) / denom\n",
    "\n",
    "    return scores\n",
    "\n",
    "# =========================\n",
    "# RM3 QUERY EXPANSION\n",
    "# =========================\n",
    "def expand_query_rm3(query, bm25_scores, documents, top_docs=5, top_terms=5):\n",
    "    top_documents = sorted(bm25_scores.items(), key=lambda x: x[1], reverse=True)[:top_docs]\n",
    "\n",
    "    term_freq = defaultdict(int)\n",
    "    for doc_id, _ in top_documents:\n",
    "        for term in preprocess(documents[doc_id]):\n",
    "            term_freq[term] += 1\n",
    "\n",
    "    expansion_terms = sorted(term_freq.items(), key=lambda x: x[1], reverse=True)[:top_terms]\n",
    "    expanded_query = query + \" \" + \" \".join([t for t, _ in expansion_terms])\n",
    "\n",
    "    return expanded_query\n",
    "\n",
    "# =========================\n",
    "# SEARCH PIPELINE\n",
    "# =========================\n",
    "def search_news(query):\n",
    "    print(\"\\nFetching news from the internet...\")\n",
    "    documents, metadata = fetch_news(query, ARTICLES_PER_QUERY)\n",
    "\n",
    "    if not documents:\n",
    "        print(\"No articles found.\")\n",
    "        return\n",
    "\n",
    "    index, doc_lengths, avg_dl = build_index(documents)\n",
    "\n",
    "    # BM25\n",
    "    bm25_scores = score_BM25(query, index, doc_lengths, avg_dl)\n",
    "\n",
    "    # RM3\n",
    "    expanded_query = expand_query_rm3(query, bm25_scores, documents)\n",
    "    rm3_scores = score_BM25(expanded_query, index, doc_lengths, avg_dl)\n",
    "\n",
    "    ranked_docs = sorted(rm3_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    print(\"\\nTOP NEWS RESULTS (BM25 + RM3)\\n\")\n",
    "    for rank, (doc_id, score) in enumerate(ranked_docs, start=1):\n",
    "        print(f\"{rank}. {metadata[doc_id]['title']}\")\n",
    "        print(f\"   Source: {metadata[doc_id]['source']}\")\n",
    "        print(f\"   URL: {metadata[doc_id]['url']}\\n\")\n",
    "\n",
    "# MAIN LOOP\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"INTERNET NEWS SEARCH ENGINE\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nEnter search query (or 'exit'): \")\n",
    "        if user_query.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        search_news(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f57110-13d9-4f10-8993-555c736c8646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
